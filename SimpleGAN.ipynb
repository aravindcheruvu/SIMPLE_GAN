{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\My_env\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\ProgramData\\Anaconda3\\envs\\My_Env\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] Batch 0/1875                                   Loss D: 0.7240, loss G: 0.7393\n",
      "Epoch [1/50] Batch 0/1875                                   Loss D: 0.7213, loss G: 0.9795\n",
      "Epoch [2/50] Batch 0/1875                                   Loss D: 0.3027, loss G: 1.5648\n",
      "Epoch [3/50] Batch 0/1875                                   Loss D: 0.5410, loss G: 0.9576\n",
      "Epoch [4/50] Batch 0/1875                                   Loss D: 0.8662, loss G: 0.7797\n",
      "Epoch [5/50] Batch 0/1875                                   Loss D: 0.9825, loss G: 0.7609\n",
      "Epoch [6/50] Batch 0/1875                                   Loss D: 0.5725, loss G: 1.2303\n",
      "Epoch [7/50] Batch 0/1875                                   Loss D: 0.6360, loss G: 1.5735\n",
      "Epoch [8/50] Batch 0/1875                                   Loss D: 0.6630, loss G: 0.9989\n",
      "Epoch [9/50] Batch 0/1875                                   Loss D: 0.7848, loss G: 0.8488\n",
      "Epoch [10/50] Batch 0/1875                                   Loss D: 0.6747, loss G: 1.0590\n",
      "Epoch [11/50] Batch 0/1875                                   Loss D: 0.5633, loss G: 1.2949\n",
      "Epoch [12/50] Batch 0/1875                                   Loss D: 0.8597, loss G: 0.8373\n",
      "Epoch [13/50] Batch 0/1875                                   Loss D: 0.5908, loss G: 1.3594\n",
      "Epoch [14/50] Batch 0/1875                                   Loss D: 0.7702, loss G: 0.7794\n",
      "Epoch [15/50] Batch 0/1875                                   Loss D: 0.4961, loss G: 1.4327\n",
      "Epoch [16/50] Batch 0/1875                                   Loss D: 0.7505, loss G: 1.1679\n",
      "Epoch [17/50] Batch 0/1875                                   Loss D: 0.6343, loss G: 0.9680\n",
      "Epoch [18/50] Batch 0/1875                                   Loss D: 0.4786, loss G: 1.1848\n",
      "Epoch [19/50] Batch 0/1875                                   Loss D: 0.8439, loss G: 0.6253\n",
      "Epoch [20/50] Batch 0/1875                                   Loss D: 0.7823, loss G: 0.6975\n",
      "Epoch [21/50] Batch 0/1875                                   Loss D: 0.7258, loss G: 0.9464\n",
      "Epoch [22/50] Batch 0/1875                                   Loss D: 0.7371, loss G: 1.4322\n",
      "Epoch [23/50] Batch 0/1875                                   Loss D: 0.6918, loss G: 1.1173\n",
      "Epoch [24/50] Batch 0/1875                                   Loss D: 0.5721, loss G: 1.1006\n",
      "Epoch [25/50] Batch 0/1875                                   Loss D: 0.5547, loss G: 1.1045\n",
      "Epoch [26/50] Batch 0/1875                                   Loss D: 0.6748, loss G: 0.8191\n",
      "Epoch [27/50] Batch 0/1875                                   Loss D: 0.6910, loss G: 0.8957\n",
      "Epoch [28/50] Batch 0/1875                                   Loss D: 0.5526, loss G: 0.8854\n",
      "Epoch [29/50] Batch 0/1875                                   Loss D: 0.6669, loss G: 0.8296\n",
      "Epoch [30/50] Batch 0/1875                                   Loss D: 0.6433, loss G: 0.8262\n",
      "Epoch [31/50] Batch 0/1875                                   Loss D: 0.5861, loss G: 1.1293\n",
      "Epoch [32/50] Batch 0/1875                                   Loss D: 0.6682, loss G: 1.2140\n",
      "Epoch [33/50] Batch 0/1875                                   Loss D: 0.7370, loss G: 0.8366\n",
      "Epoch [34/50] Batch 0/1875                                   Loss D: 0.5928, loss G: 0.8790\n",
      "Epoch [35/50] Batch 0/1875                                   Loss D: 0.5467, loss G: 1.2051\n",
      "Epoch [36/50] Batch 0/1875                                   Loss D: 0.6434, loss G: 0.9708\n",
      "Epoch [37/50] Batch 0/1875                                   Loss D: 0.6570, loss G: 1.0166\n",
      "Epoch [38/50] Batch 0/1875                                   Loss D: 0.6919, loss G: 0.8637\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,img_dim):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim,128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(128,1),\n",
    "            nn.Sigmoid()\n",
    "             )\n",
    "    def forward(self,x):\n",
    "        return self.disc(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,z_dim,img_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim,256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256,img_dim),\n",
    "            nn.Tanh()\n",
    "              )\n",
    "\n",
    "    def forward(self,x):\n",
    "         return self.gen(x)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 5e-4\n",
    "z_dim = 64\n",
    "image_dim = 28 * 28 * 1\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "\n",
    "disc = Discriminator(image_dim).to(device)\n",
    "gen = Generator(z_dim,image_dim).to(device)\n",
    "fixed_noise = torch.randn(batch_size,z_dim).to(device)\n",
    "transform = transforms.Compose(\n",
    "[transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))]\n",
    ")\n",
    "dataset = datasets.MNIST(root = \"dataset/\", transform = transform,download=True)\n",
    "loader = DataLoader(dataset, batch_size=batch_size,shuffle=True)\n",
    "opt_disc = optim.Adam(disc.parameters(),lr =lr)\n",
    "opt_gen = optim.Adam(gen.parameters(),lr = lr)\n",
    "criterion = nn.BCELoss()\n",
    "writer_fake = SummaryWriter(f\"runs/GAN_MNIST/fake\")\n",
    "writer_real = SummaryWriter(f\"runs/GAN_MNIST/real\")\n",
    "step = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real,_) in enumerate(loader):\n",
    "            real = real.view(-1,784).to(device)\n",
    "            batch_size = real.shape[0]\n",
    "\n",
    "            noise = torch.randn((batch_size,z_dim)).to(device)\n",
    "            fake = gen(noise)\n",
    "            disc_real = disc(real).view(-1)\n",
    "            lossD_real = criterion(disc_real,torch.ones_like(disc_real))\n",
    "            disc_fake = disc(fake).view(-1)\n",
    "            lossD_fake = criterion(disc_fake,torch.zeros_like(disc_fake))\n",
    "            lossD = (lossD_fake + lossD_real)/2\n",
    "            disc.zero_grad()\n",
    "            lossD.backward(retain_graph = True)\n",
    "\n",
    "            opt_disc.step()\n",
    "\n",
    "            output = disc(fake).view(-1)\n",
    "            lossG = criterion(output,torch.ones_like(output))\n",
    "            gen.zero_grad()\n",
    "            lossG.backward()\n",
    "            opt_gen.step()\n",
    "\n",
    "            if batch_idx == 0:\n",
    "                        print(\n",
    "                            f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n",
    "                                  Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\n",
    "                        )\n",
    "\n",
    "                        with torch.no_grad():\n",
    "                            fake = gen(fixed_noise).reshape(-1, 1, 28, 28)\n",
    "                            data = real.reshape(-1, 1, 28, 28)\n",
    "\n",
    "                            img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
    "                            img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n",
    "\n",
    "                            # print(type(img_grid_fake.cpu().detach().numpy()))\n",
    "                            # writer_fake.add_image(\n",
    "                            #     \"Mnist Fake Images\", img_grid_fake, global_step=step\n",
    "                            # )\n",
    "                            # writer_real.add_image(\n",
    "                            #     \"Mnist Real Images\", img_grid_real, global_step=step\n",
    "                            # )\n",
    "                            plt.imshow(img_grid_fake.cpu().permute(1, 2, 0))\n",
    "\n",
    "\n",
    "                            step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
